{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to SQLAlchemy and Gevent\n",
    "The following code was written to use the pgbench database. In this case it was created with the following command: `pgbench -i -s 400 pgbench`. The timings in this file were from a Macbook Pro 2017 with an i5 running at 2.5Ghz and 8GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData, create_engine\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "metadata = MetaData()\n",
    "Base = automap_base()\n",
    "engine = create_engine('postgresql+psycopg2://jasonmyers@localhost:5432/pgbench')\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accounts = Base.classes.pgbench_accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import func\n",
    "query = session.query(Accounts.bid, func.count(1)).group_by(Accounts.bid).limit(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query():\n",
    "    query.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "CPU times: user 3.08 ms, sys: 1.54 ms, total: 4.62 ms\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(execute_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "def async_creation_runner(cache, somekey, creator, mutex):\n",
    "    def runner():\n",
    "        try:\n",
    "            value = creator()\n",
    "            cache.set(somekey, value)\n",
    "        finally:\n",
    "            mutex.release()\n",
    "\n",
    "    thread = threading.Thread(target=runner)\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dogpile.cache.util import sha1_mangle_key\n",
    "def unicode_sha1_mangle_key(key):\n",
    "    return sha1_mangle_key(key.encode('ascii', 'ignore'))\n",
    "\n",
    "\n",
    "def mangle_key(key):\n",
    "    prefix, key = key.split(':', 1)\n",
    "    base = 'cookie:cache:'\n",
    "    if prefix:\n",
    "        base += '{}'.format(prefix)\n",
    "    else:\n",
    "        raise ValueError(key)\n",
    "    value = '{}:{}'.format(base, unicode_sha1_mangle_key(key))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dogpile.cache import make_region\n",
    "regions = {}\n",
    "\n",
    "regions['default'] = make_region(async_creation_runner=async_creation_runner,\n",
    "                                 key_mangler=mangle_key).configure(\n",
    "    'dogpile.cache.redis',\n",
    "    arguments={\n",
    "        'host': 'localhost',\n",
    "        'port': 6379,\n",
    "        'db': 0,\n",
    "        'redis_expiration_time': 60*60*2,   # 2 hours\n",
    "        'distributed_lock': True,\n",
    "        'lock_timeout': 120,\n",
    "        'lock_sleep': 5\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _key_from_query(query, qualifier=None):\n",
    "    stmt = query.with_labels().statement\n",
    "    compiled = stmt.compile()\n",
    "    params = compiled.params\n",
    "\n",
    "    return \" \".join([str(compiled)] +\n",
    "                    [str(params[k]) for k in sorted(params)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm.query import Query\n",
    "from dogpile.cache.api import NO_VALUE\n",
    "\n",
    "\n",
    "class CachingQuery(Query):\n",
    "\n",
    "    def __init__(self, regions, *args, **kw):\n",
    "        self.cache_regions = regions\n",
    "        self.saved_to_cache = False\n",
    "        Query.__init__(self, *args, **kw)\n",
    "\n",
    "    def __iter__(self):\n",
    "        if hasattr(self, '_cache_region'):\n",
    "            return self.get_value(\n",
    "                createfunc=lambda: list(Query.__iter__(self)))\n",
    "        else:\n",
    "            return Query.__iter__(self)\n",
    "        \n",
    "    def _get_cache_plus_key(self):\n",
    "        dogpile_region = self.cache_regions[self._cache_region.region]\n",
    "        if self._cache_region.cache_key:\n",
    "            key = self._cache_region.cache_key\n",
    "        else:\n",
    "            key = _key_from_query(self)\n",
    "        return dogpile_region, key\n",
    "    \n",
    "    def get_value(self, merge=True, createfunc=None,\n",
    "                  expiration_time=None, ignore_expiration=False):\n",
    "        dogpile_region, cache_key = self._get_cache_plus_key()\n",
    "\n",
    "        assert not ignore_expiration or not createfunc, \\\n",
    "            \"Can't ignore expiration and also provide createfunc\"\n",
    "\n",
    "        if ignore_expiration or not createfunc:\n",
    "            cached_value = dogpile_region.get(\n",
    "                cache_key,\n",
    "                expiration_time=expiration_time,\n",
    "                ignore_expiration=ignore_expiration\n",
    "            )\n",
    "        else:\n",
    "            try:\n",
    "                cached_value = dogpile_region.get_or_create(\n",
    "                    cache_key,\n",
    "                    createfunc,\n",
    "                    expiration_time=expiration_time\n",
    "                )\n",
    "            except ConnectionError:\n",
    "                logger.error('Cannot connect to query caching backend!')\n",
    "                cached_value = createfunc()\n",
    "        if cached_value is NO_VALUE:\n",
    "            raise KeyError(cache_key)\n",
    "        if merge:\n",
    "            cached_value = self.merge_result(cached_value, load=False)\n",
    "        return cached_value\n",
    "    \n",
    "    def set_value(self, value):\n",
    "        dogpile_region, cache_key = self._get_cache_plus_key()\n",
    "        try:\n",
    "            dogpile_region.set(cache_key, value)\n",
    "            self.saved_to_cache = True\n",
    "        except ConnectionError:\n",
    "            logger.error('Cannot connect to query caching backend!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm.interfaces import MapperOption\n",
    "\n",
    "class FromCache(MapperOption):\n",
    "    \"\"\"Specifies that a Query should load results from a cache.\"\"\"\n",
    "\n",
    "    propagate_to_loaders = False\n",
    "\n",
    "    def __init__(self, region=\"default\", cache_key=None, cache_prefix=None):\n",
    "        self.region = region\n",
    "        self.cache_key = cache_key\n",
    "        self.cache_prefix = cache_prefix\n",
    "\n",
    "    def process_query(self, query):\n",
    "        query._cache_region = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_callable(regions, query_cls=CachingQuery):\n",
    "    def query(*arg, **kw):\n",
    "        return query_cls(regions, *arg, **kw)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "def init_caching_session(engine=None):\n",
    "    if not engine:\n",
    "        return\n",
    "\n",
    "    return sessionmaker(\n",
    "        bind=engine, autoflush=False, autocommit=False,\n",
    "        query_cls=query_callable(regions)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CachingSession = init_caching_session(engine)\n",
    "caching_session=CachingSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = caching_session.query(Accounts.bid, func.count(1)).group_by(Accounts.bid).limit(5000).options(\n",
    "            FromCache('default'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "CPU times: user 10.4 ms, sys: 7.3 ms, total: 17.7 ms\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(execute_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "CPU times: user 3.5 ms, sys: 1.62 ms, total: 5.11 ms\n",
      "Wall time: 4.32 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(execute_query())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
